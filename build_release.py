#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FastBlog å‘å¸ƒæ„å»ºè„šæœ¬
è´Ÿè´£æ‰“åŒ…æ•´ä¸ªé¡¹ç›®ä¸ºå¯å‘å¸ƒçš„å‘è¡Œç‰ˆæœ¬
æ”¯æŒä» Git æäº¤å†å²è‡ªåŠ¨ç”Ÿæˆå‘å¸ƒè¯´æ˜ï¼ˆå«å¤šè¡Œ bodyï¼‰
"""

import argparse
import hashlib
import json
import logging
import os
import platform
import re
import shutil
import subprocess
import sys
import tempfile
import time
import zipfile
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def get_current_version():
    """è·å–å½“å‰ç‰ˆæœ¬å·"""
    try:
        with open('version.txt', 'r', encoding='utf-8') as f:
            return f.read().strip()
    except FileNotFoundError:
        return '1.0.0'


def get_backend_versions():
    """è·å–åç«¯ä¾èµ–ç‰ˆæœ¬ä¿¡æ¯"""
    versions = []

    # è·å–Pythonç‰ˆæœ¬
    versions.append(f"- Pythonç‰ˆæœ¬: {platform.python_version()}")

    # ä»requirements.txtè¯»å–ä¸»è¦ä¾èµ–ç‰ˆæœ¬
    try:
        with open('requirements.txt', 'r', encoding='utf-8') as f:
            requirements = f.readlines()

        important_packages = [
            'fastapi', 'uvicorn', 'sqlalchemy', 'pydantic',
            'alembic', 'passlib', 'python-jose', 'python-multipart',
            'pillow', 'requests', 'aiofiles'
        ]

        found_packages = []
        for req in requirements:
            req = req.strip()
            if req and not req.startswith('#'):
                for package in important_packages:
                    if req.lower().startswith(package):
                        # æå–åŒ…åå’Œç‰ˆæœ¬
                        if '==' in req:
                            pkg_name, version = req.split('==', 1)
                            found_packages.append((pkg_name.strip(), version.strip()))
                        elif '>=' in req:
                            pkg_name, version = req.split('>=', 1)
                            found_packages.append((pkg_name.strip(), f">={version.strip()}"))
                        elif '<' in req:
                            pkg_name, version = req.split('<', 1)
                            found_packages.append((pkg_name.strip(), f"<{version.strip()}"))
                        else:
                            found_packages.append((req, 'latest'))
                        break

        # æŒ‰å­—æ¯é¡ºåºæ’åº
        found_packages.sort(key=lambda x: x[0].lower())
        for pkg_name, version in found_packages:
            versions.append(f"- {pkg_name}: {version}")

    except FileNotFoundError:
        versions.append("- æ— æ³•è¯»å–requirements.txt")
    except Exception as e:
        versions.append(f"- è¯»å–ä¾èµ–ä¿¡æ¯å‡ºé”™: {str(e)}")

    return versions


def get_frontend_versions():
    """è·å–å‰ç«¯ä¾èµ–ç‰ˆæœ¬ä¿¡æ¯"""
    versions = []

    try:
        with open('frontend-next/package.json', 'r', encoding='utf-8') as f:
            package_data = json.load(f)

        # è·å–æ ¸å¿ƒæ¡†æ¶ç‰ˆæœ¬
        core_deps = ['next', 'react', 'react-dom']
        for dep in core_deps:
            version = package_data.get('dependencies', {}).get(dep, 'unknown')
            if version != 'unknown':
                versions.append(f"- {dep.capitalize()}: {version}")

        # è·å–å¼€å‘ä¾èµ–ä¸­çš„é‡è¦å·¥å…·
        dev_tools = ['typescript', '@types/react', '@types/node']
        for dep in dev_tools:
            version = package_data.get('devDependencies', {}).get(dep) or \
                      package_data.get('dependencies', {}).get(dep, 'unknown')
            if version != 'unknown':
                versions.append(f"- {dep}: {version}")

        # è·å–UIç›¸å…³ä¾èµ–
        ui_deps = ['tailwindcss', 'postcss', 'autoprefixer']
        for dep in ui_deps:
            version = package_data.get('devDependencies', {}).get(dep) or \
                      package_data.get('dependencies', {}).get(dep)
            if version:
                versions.append(f"- {dep}: {version}")

    except FileNotFoundError:
        versions.append("- æ— æ³•è¯»å–package.json")
    except json.JSONDecodeError:
        versions.append("- package.jsonæ ¼å¼é”™è¯¯")
    except Exception as e:
        versions.append(f"- è¯»å–å‰ç«¯ä¾èµ–å‡ºé”™: {str(e)}")

    return versions


def format_version_list(versions):
    """æ ¼å¼åŒ–ç‰ˆæœ¬åˆ—è¡¨ä¸ºå­—ç¬¦ä¸²"""
    if not versions:
        return "- æš‚æ— ç‰ˆæœ¬ä¿¡æ¯"
    return '\n'.join(versions)


class ReleaseBuilder:
    """å‘å¸ƒæ„å»ºå™¨"""

    def __init__(self, version: str, output_dir: str = "release"):
        self.version = version
        self.output_dir = Path(output_dir)
        self.project_root = Path(__file__).resolve().parent
        self.build_temp = Path(tempfile.mkdtemp(prefix="fastblog_build_"))
        self.release_dir = self.output_dir / f"fastblog-v{version}"

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(exist_ok=True)
        self.release_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"æ„å»ºç‰ˆæœ¬: {version}")
        logger.info(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        logger.info(f"å‘å¸ƒç›®å½•: {self.release_dir}")

    def get_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶SHA256å“ˆå¸Œå€¼"""
        hash_sha256 = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_sha256.update(chunk)
        return hash_sha256.hexdigest()

    def copy_backend_files(self) -> List[Path]:
        """å¤åˆ¶åç«¯æ–‡ä»¶"""
        logger.info("æ­£åœ¨å¤åˆ¶åç«¯æ–‡ä»¶...")

        backend_files = []
        backend_dirs = ['src', 'ipc', 'launcher', 'updater']
        backend_files_list = ['main.py', 'start_fastblog.py', 'requirements.txt',
                              'version.txt', '.env_example']

        # å¤åˆ¶ç›®å½•
        for dir_name in backend_dirs:
            src_dir = self.project_root / dir_name
            if src_dir.exists():
                dst_dir = self.release_dir / dir_name
                shutil.copytree(src_dir, dst_dir, dirs_exist_ok=True)
                # æ”¶é›†æ‰€æœ‰æ–‡ä»¶
                for root, dirs, files in os.walk(dst_dir):
                    for file in files:
                        backend_files.append(Path(root) / file)
                logger.info(f"å·²å¤åˆ¶ç›®å½•: {dir_name}")

        # å¤åˆ¶å•ç‹¬æ–‡ä»¶
        for file_name in backend_files_list:
            src_file = self.project_root / file_name
            if src_file.exists():
                dst_file = self.release_dir / file_name
                shutil.copy2(src_file, dst_file)
                backend_files.append(dst_file)
                logger.info(f"å·²å¤åˆ¶æ–‡ä»¶: {file_name}")

        return backend_files

    def build_frontend(self) -> List[Path]:
        """æ„å»ºå‰ç«¯åº”ç”¨"""
        logger.info("æ­£åœ¨æ„å»ºå‰ç«¯åº”ç”¨...")

        frontend_files = []
        frontend_dir = self.project_root / "frontend-next"

        if not frontend_dir.exists():
            logger.warning("å‰ç«¯ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å‰ç«¯æ„å»º")
            return frontend_files

        try:
            # æ„å»ºNext.jsåº”ç”¨
            build_cmd = ["npm", "run", "build"]
            result = subprocess.run(
                build_cmd,
                cwd=frontend_dir,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )

            if result.returncode != 0:
                logger.error(f"å‰ç«¯æ„å»ºå¤±è´¥: {result.stderr}")
                raise Exception("å‰ç«¯æ„å»ºå¤±è´¥")

            logger.info("å‰ç«¯æ„å»ºå®Œæˆ")

            # å¤åˆ¶æ„å»ºäº§ç‰©
            next_dir = frontend_dir / ".next"
            if next_dir.exists():
                dst_next_dir = self.release_dir / "frontend-next" / ".next"
                shutil.copytree(next_dir, dst_next_dir, dirs_exist_ok=True)
                # æ”¶é›†æ„å»ºæ–‡ä»¶
                for root, dirs, files in os.walk(dst_next_dir):
                    for file in files:
                        frontend_files.append(Path(root) / file)

            # å¤åˆ¶å…¶ä»–å¿…è¦æ–‡ä»¶
            frontend_files_needed = [
                'package.json', 'next.config.ts', 'tsconfig.json',
                '.env_example', '.gitignore'
            ]

            for file_name in frontend_files_needed:
                src_file = frontend_dir / file_name
                if src_file.exists():
                    dst_file = self.release_dir / "frontend-next" / file_name
                    dst_file.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(src_file, dst_file)
                    frontend_files.append(dst_file)

            logger.info(f"å·²å¤åˆ¶ {len(frontend_files)} ä¸ªå‰ç«¯æ–‡ä»¶")

        except subprocess.TimeoutExpired:
            logger.error("å‰ç«¯æ„å»ºè¶…æ—¶")
            raise Exception("å‰ç«¯æ„å»ºè¶…æ—¶")
        except Exception as e:
            logger.error(f"å‰ç«¯æ„å»ºå¼‚å¸¸: {e}")
            raise

        return frontend_files

    def copy_static_assets(self) -> List[Path]:
        """å¤åˆ¶é™æ€èµ„æº"""
        logger.info("æ­£åœ¨å¤åˆ¶é™æ€èµ„æº...")

        static_files = []
        static_dir = self.project_root / "static"

        if static_dir.exists():
            dst_static_dir = self.release_dir / "static"
            shutil.copytree(static_dir, dst_static_dir, dirs_exist_ok=True)

            # æ”¶é›†é™æ€æ–‡ä»¶
            for root, dirs, files in os.walk(dst_static_dir):
                for file in files:
                    static_files.append(Path(root) / file)

            logger.info(f"å·²å¤åˆ¶ {len(static_files)} ä¸ªé™æ€æ–‡ä»¶")

        return static_files

    def create_startup_scripts(self) -> List[Path]:
        """åˆ›å»ºå¯åŠ¨è„šæœ¬"""
        logger.info("æ­£åœ¨åˆ›å»ºå¯åŠ¨è„šæœ¬...")

        scripts = []

        # Windowsæ‰¹å¤„ç†è„šæœ¬
        win_script = self.release_dir / "start_fastblog.bat"
        win_script_content = f"""@echo off
REM FastBlog {self.version} å¯åŠ¨è„šæœ¬ (Windows)
cd /d "%~dp0"
python start_fastblog.py
pause
"""
        with open(win_script, 'w', encoding='utf-8') as f:
            f.write(win_script_content)
        scripts.append(win_script)

        # Linux/Mac Shellè„šæœ¬
        unix_script = self.release_dir / "start_fastblog.sh"
        unix_script_content = f"""#!/bin/bash
# FastBlog {self.version} å¯åŠ¨è„šæœ¬ (Linux/macOS)
cd "$(dirname "$0")"
python3 start_fastblog.py
"""
        with open(unix_script, 'w', encoding='utf-8') as f:
            f.write(unix_script_content)
        os.chmod(unix_script, 0o755)  # è®¾ç½®æ‰§è¡Œæƒé™
        scripts.append(unix_script)

        # READMEæ–‡ä»¶
        readme_file = self.release_dir / "README.md"
        readme_content = f"""# FastBlog v{self.version}

## ç®€ä»‹
FastBlog æ˜¯ä¸€ä¸ªç°ä»£åŒ–çš„åšå®¢ç³»ç»Ÿï¼ŒåŸºäºFastAPIå’ŒNext.jsæ„å»ºã€‚

## ç³»ç»Ÿè¦æ±‚
- Python 3.8+
- Node.js 18+ (å¦‚æœéœ€è¦é‡æ–°æ„å»ºå‰ç«¯)
- æ•°æ®åº“æ”¯æŒ: PostgreSQL, MySQL, SQLite

## å®‰è£…æ­¥éª¤

### 1. å®‰è£…Pythonä¾èµ–
```bash
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒ
å¤åˆ¶ `.env_example` ä¸º `.env` å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹é…ç½®ï¼š
```bash
cp .env_example .env
```

### 3. å¯åŠ¨åº”ç”¨
Windows:
```cmd
start_fastblog.bat
```

Linux/macOS:
```bash
./start_fastblog.sh
```

æˆ–è€…ç›´æ¥è¿è¡Œï¼š
```bash
python start_fastblog.py
```

## ç›®å½•ç»“æ„
- `src/` - åç«¯æºä»£ç 
- `frontend-next/` - å‰ç«¯æºä»£ç 
- `launcher/` - åº”ç”¨å¯åŠ¨å™¨
- `updater/` - è‡ªåŠ¨æ›´æ–°ç³»ç»Ÿ
- `static/` - é™æ€èµ„æºæ–‡ä»¶

## è®¿é—®åœ°å€
é»˜è®¤æƒ…å†µä¸‹ï¼Œåº”ç”¨å°†åœ¨ä»¥ä¸‹åœ°å€è¿è¡Œï¼š
- å‰ç«¯ç•Œé¢: http://localhost:3000
- APIæ–‡æ¡£: http://localhost:8000/docs

## æ›´å¤šä¿¡æ¯
è¯·è®¿é—®é¡¹ç›®æ–‡æ¡£è·å–è¯¦ç»†ä¿¡æ¯ã€‚
"""
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        scripts.append(readme_file)

        logger.info(f"å·²åˆ›å»º {len(scripts)} ä¸ªå¯åŠ¨è„šæœ¬å’Œæ–‡æ¡£")
        return scripts

    def create_checksums(self, all_files: List[Path]) -> Path:
        """åˆ›å»ºæ ¡éªŒå’Œæ–‡ä»¶"""
        logger.info("æ­£åœ¨åˆ›å»ºæ ¡éªŒå’Œæ–‡ä»¶...")

        checksums = {}
        for file_path in all_files:
            try:
                rel_path = file_path.relative_to(self.release_dir)
                file_hash = self.get_file_hash(file_path)
                checksums[str(rel_path).replace('\\', '/')] = file_hash
            except Exception as e:
                logger.warning(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")

        # å†™å…¥JSONæ ¼å¼çš„æ ¡éªŒå’Œæ–‡ä»¶
        checksum_file = self.release_dir / "CHECKSUMS.json"
        with open(checksum_file, 'w', encoding='utf-8') as f:
            json.dump(checksums, f, indent=2, ensure_ascii=False)

        # å†™å…¥ä¼ ç»Ÿæ ¼å¼çš„æ ¡éªŒå’Œæ–‡ä»¶
        checksum_txt = self.release_dir / "CHECKSUMS.txt"
        with open(checksum_txt, 'w', encoding='utf-8') as f:
            for file_path, file_hash in checksums.items():
                f.write(f"{file_hash}  {file_path}\n")

        logger.info(f"æ ¡éªŒå’Œæ–‡ä»¶å·²åˆ›å»º: {checksum_file}")
        return checksum_file

    def parse_commit_message(self, subject: str) -> Optional[Dict]:
        """è§£æçº¦å®šå¼æäº¤çš„æ¶ˆæ¯ï¼Œè¿”å›ç±»å‹ã€ä½œç”¨åŸŸã€æ˜¯å¦ç ´åæ€§å˜æ›´å’Œä¸»é¢˜"""
        pattern = r'^(?P<type>\w+)(?:\((?P<scope>[\w-]+)\))?(?P<breaking>!)?:\s*(?P<subject>.+)$'
        match = re.match(pattern, subject)
        if match:
            return {
                'type': match.group('type'),
                'scope': match.group('scope'),
                'breaking': bool(match.group('breaking')),
                'subject': match.group('subject').strip()
            }
        return None

    def get_commits_since_last_tag(self) -> List[Dict]:
        """è·å–ä»ä¸Šä¸€ä¸ªæ ‡ç­¾åˆ°å½“å‰ç‰ˆæœ¬æ ‡ç­¾ä¹‹é—´çš„æäº¤ä¿¡æ¯ï¼ˆæ”¯æŒ v å’Œ V å‰ç¼€ï¼‰"""
        commits = []
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨ Git ä»“åº“ä¸­
            subprocess.run(["git", "rev-parse", "--git-dir"], check=True,
                           capture_output=True, encoding='utf-8')

            # å°è¯•ä¸¤ç§å‰ç¼€ï¼Œæ‰¾åˆ°å®é™…å­˜åœ¨çš„æ ‡ç­¾
            possible_tags = [f"v{self.version}", f"V{self.version}"]
            current_tag = None
            for tag in possible_tags:
                try:
                    subprocess.run(["git", "rev-parse", tag], check=True,
                                   capture_output=True, encoding='utf-8')
                    current_tag = tag
                    break
                except subprocess.CalledProcessError:
                    continue

            if not current_tag:
                logger.warning(f"æœªæ‰¾åˆ°ä¸ç‰ˆæœ¬ {self.version} åŒ¹é…çš„æ ‡ç­¾ï¼ˆå°è¯•äº† {possible_tags}ï¼‰")
                return commits

            # è·å–ä¸Šä¸€ä¸ªæ ‡ç­¾
            prev_tag = None
            try:
                result = subprocess.run(
                    ["git", "describe", "--tags", "--abbrev=0", f"{current_tag}^"],
                    check=True, capture_output=True, text=True, encoding='utf-8'
                )
                prev_tag = result.stdout.strip()
            except subprocess.CalledProcessError:
                # æ²¡æœ‰ä¸Šä¸€ä¸ªæ ‡ç­¾ï¼Œåˆ™è·å–æ‰€æœ‰æäº¤ç›´åˆ°å½“å‰æ ‡ç­¾
                prev_tag = ""

            # æ„å»º commit èŒƒå›´
            rev_range = f"{prev_tag}..{current_tag}" if prev_tag else current_tag

            # è·å–æ¯ä¸ª commit çš„ hashã€subject å’Œ bodyï¼Œç”¨ --- åˆ†éš”
            result = subprocess.run(
                ["git", "log", "--pretty=format:%H%n%s%n%b%n---", rev_range],
                check=True, capture_output=True, text=True, encoding='utf-8'
            )
            raw = result.stdout.strip()
            entries = raw.split("\n---\n")
            for entry in entries:
                if not entry.strip():
                    continue
                lines = entry.strip().split("\n")
                if len(lines) >= 3:
                    commit_hash = lines[0]
                    subject = lines[1]
                    body = "\n".join(lines[2:])
                    parsed = self.parse_commit_message(subject)
                    if parsed:
                        parsed['hash'] = commit_hash[:8]  # çŸ­ hash
                        parsed['body'] = body.strip()
                        commits.append(parsed)
        except (subprocess.CalledProcessError, FileNotFoundError) as e:
            logger.warning(f"æ— æ³•è·å– Git æäº¤ä¿¡æ¯: {e}")
        return commits

    def _format_commit_entry(self, commit: Dict) -> str:
        """æ ¼å¼åŒ–å•ä¸ªæäº¤æ¡ç›®ï¼ŒåŒ…å«å¯é€‰çš„ body è¯¦ç»†ä¿¡æ¯"""
        scope = commit.get('scope')
        subject = commit['subject']
        hash_short = commit['hash']
        body = commit.get('body', '')

        # æ„å»ºä¸»æ¡ç›®
        if scope:
            entry = f"- **{scope}**: {subject} ({hash_short})"
        else:
            entry = f"- {subject} ({hash_short})"

        # å¦‚æœæœ‰ bodyï¼Œå°†å…¶æ‹†åˆ†ä¸ºå¤šè¡Œå¹¶ä½œä¸ºç¼©è¿›çš„å­åˆ—è¡¨æ·»åŠ 
        if body:
            body_lines = [line.strip() for line in body.split('\n') if line.strip()]
            if body_lines:
                # æ¯ä¸ª body è¡Œå‰åŠ  4 ä¸ªç©ºæ ¼å’Œä¸€ä¸ªçŸ­æ¨ªï¼Œå½¢æˆåµŒå¥—åˆ—è¡¨
                body_formatted = "\n".join([f"    - {line}" for line in body_lines])
                entry += f"\n{body_formatted}"

        return entry

    def create_release_notes(self) -> Path:
        """åˆ›å»ºå‘å¸ƒè¯´æ˜ï¼Œè‡ªåŠ¨å¡«å……ä» commit æå–çš„å†…å®¹ï¼ˆæ”¯æŒå¤šè¡Œ bodyï¼‰"""
        logger.info("æ­£åœ¨åˆ›å»ºå‘å¸ƒè¯´æ˜...")

        # è·å–åç«¯å’Œå‰ç«¯ç‰ˆæœ¬ä¿¡æ¯
        backend_versions = get_backend_versions()
        frontend_versions = get_frontend_versions()

        # è·å–æäº¤ä¿¡æ¯å¹¶åˆ†ç±»
        commits = self.get_commits_since_last_tag()
        features = []
        fixes = []
        docs = []
        perfs = []
        breaking_changes = []

        for c in commits:
            # å¤„ç†ç ´åæ€§å˜æ›´ï¼ˆæ— è®ºç±»å‹ï¼Œåªè¦æœ‰ ! æ ‡è®°ï¼‰
            if c['breaking']:
                breaking_changes.append(self._format_commit_entry(c))
            # æŒ‰ç±»å‹åˆ†ç±»
            if c['type'] == 'feat':
                features.append(self._format_commit_entry(c))
            elif c['type'] == 'fix':
                fixes.append(self._format_commit_entry(c))
            elif c['type'] == 'docs':
                docs.append(self._format_commit_entry(c))
            elif c['type'] == 'perf':
                perfs.append(self._format_commit_entry(c))
            # å…¶ä»–ç±»å‹å¯å¿½ç•¥æˆ–æŒ‰éœ€æ·»åŠ 

        # è‹¥æ— å¯¹åº”æäº¤ï¼Œä½¿ç”¨å ä½ç¬¦
        if not features:
            features = ["- [åœ¨æ­¤å¤„æ·»åŠ æ–°åŠŸèƒ½æè¿°]"]
        if not fixes:
            fixes = ["- [åœ¨æ­¤å¤„æ·»åŠ ä¿®å¤çš„é—®é¢˜]"]
        if not perfs:
            perfs = ["- [åœ¨æ­¤å¤„æ·»åŠ æ€§èƒ½æ”¹è¿›]"]
        if not docs:
            docs = []  # æ–‡æ¡£æ›´æ–°å¯é€‰ï¼Œä¸å¼ºåˆ¶æ˜¾ç¤º
        if not breaking_changes:
            breaking_changes = ["- æ— ç ´åæ€§å˜æ›´"]

        # æ„å»ºå„éƒ¨åˆ†å†…å®¹
        features_section = "\n".join(features)
        fixes_section = "\n".join(fixes)
        perfs_section = "\n".join(perfs)
        docs_section = "\n".join(docs) if docs else "æ— "
        breaking_section = "\n".join(breaking_changes)

        release_notes = self.release_dir / "RELEASE_NOTES.md"
        notes_content = f"""# FastBlog v{self.version} å‘å¸ƒè¯´æ˜

## ğŸ‰ æ–°ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
{features_section}

### æ€§èƒ½ä¼˜åŒ–
{perfs_section}

### æ–‡æ¡£æ›´æ–°
{docs_section}

## ğŸ› é—®é¢˜ä¿®å¤

{fixes_section}

## âš ï¸ ç ´åæ€§å˜æ›´

{breaking_section}

## ğŸ”§ å·¥ä½œæµé…ç½®

### åç«¯æ›´æ–°
{format_version_list(backend_versions)}

### å‰ç«¯æ›´æ–°
{format_version_list(frontend_versions)}

## ğŸ“¦ å®‰è£…è¯´æ˜

è¯·å‚è€ƒ README.md æ–‡ä»¶è·å–è¯¦ç»†çš„å®‰è£…å’Œé…ç½®è¯´æ˜ã€‚

## ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰ä¸ºæ­¤ç‰ˆæœ¬åšå‡ºè´¡çŒ®çš„å¼€å‘è€…ï¼

---
å‘å¸ƒæ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"""

        with open(release_notes, 'w', encoding='utf-8') as f:
            f.write(notes_content)
        logger.info(f"å‘å¸ƒè¯´æ˜å·²åˆ›å»º: {release_notes}")
        return release_notes

    def build(self) -> Dict[str, any]:
        """æ‰§è¡Œå®Œæ•´æ„å»ºæµç¨‹"""
        logger.info("=== å¼€å§‹æ„å»ºå‘å¸ƒç‰ˆæœ¬ ===")
        start_time = time.time()

        try:
            # 1. å¤åˆ¶åç«¯æ–‡ä»¶
            backend_files = self.copy_backend_files()

            # 2. æ„å»ºå‰ç«¯
            frontend_files = self.build_frontend()

            # 3. å¤åˆ¶é™æ€èµ„æº
            static_files = self.copy_static_assets()

            # 4. åˆ›å»ºå¯åŠ¨è„šæœ¬
            script_files = self.create_startup_scripts()

            # 5. æ”¶é›†æ‰€æœ‰æ–‡ä»¶
            all_files = backend_files + frontend_files + static_files + script_files

            # 6. åˆ›å»ºæ ¡éªŒå’Œ
            checksum_file = self.create_checksums(all_files)
            all_files.append(checksum_file)

            # 7. åˆ›å»ºå‘å¸ƒè¯´æ˜
            release_notes = self.create_release_notes()
            all_files.append(release_notes)

            # 8. åˆ›å»ºZIPåŒ…
            zip_file = self.create_zip_package()

            # 9. åˆ›å»ºé¢å¤–çš„æ ¡éªŒå’Œæ–‡ä»¶ï¼ˆé’ˆå¯¹ZIPåŒ…ï¼‰
            zip_checksum_file = self.output_dir / f"fastblog-v{self.version}-checksums.txt"
            zip_hash = self.get_file_hash(zip_file)
            with open(zip_checksum_file, 'w', encoding='utf-8') as f:
                f.write(f"{zip_hash}  fastblog-v{self.version}.zip\n")

            build_time = time.time() - start_time

            result = {
                'success': True,
                'version': self.version,
                'files_count': len(all_files),
                'zip_file': str(zip_file),
                'zip_size_mb': round(zip_file.stat().st_size / (1024 * 1024), 2),
                'build_time_seconds': round(build_time, 2),
                'release_dir': str(self.release_dir)
            }

            logger.info("=== æ„å»ºå®Œæˆ ===")
            logger.info(f"ç‰ˆæœ¬: {result['version']}")
            logger.info(f"æ–‡ä»¶æ•°é‡: {result['files_count']}")
            logger.info(f"ZIPåŒ…å¤§å°: {result['zip_size_mb']} MB")
            logger.info(f"æ„å»ºè€—æ—¶: {result['build_time_seconds']} ç§’")

            return result

        except Exception as e:
            logger.error(f"æ„å»ºå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(self.build_temp, ignore_errors=True)
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")

    def create_zip_package(self) -> Path:
        """åˆ›å»ºZIPå‹ç¼©åŒ…"""
        logger.info("æ­£åœ¨åˆ›å»ºZIPå‹ç¼©åŒ…...")

        zip_filename = self.output_dir / f"fastblog-v{self.version}.zip"

        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(self.release_dir):
                for file in files:
                    file_path = Path(root) / file
                    arc_name = file_path.relative_to(self.output_dir)
                    zipf.write(file_path, arc_name)

        logger.info(f"ZIPåŒ…å·²åˆ›å»º: {zip_filename}")
        return zip_filename


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='FastBlog å‘å¸ƒæ„å»ºå·¥å…·')
    parser.add_argument('--version', '-v', required=True, help='ç‰ˆæœ¬å·')
    parser.add_argument('--output', '-o', default='release', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    builder = ReleaseBuilder(args.version, args.output)
    result = builder.build()

    if result['success']:
        print(json.dumps(result, indent=2, ensure_ascii=False))
        sys.exit(0)
    else:
        print(f"æ„å»ºå¤±è´¥: {result['error']}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()